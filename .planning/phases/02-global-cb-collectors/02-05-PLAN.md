---
phase: 02-global-cb-collectors
plan: 05
type: execute
wave: 1
depends_on: []
files_modified: [src/liquidity/collectors/pboc.py, pyproject.toml, tests/integration/test_global_cb_collectors.py]
autonomous: true
---

<objective>
Create People's Bank of China collector with scraping and FRED fallback.

Purpose: PBoC has no public API. Primary approach scrapes official HTM/XLS files. Fallback uses FRED TRESEGCNM052N (China foreign reserves) as a proxy, matching Apps Script v3.4.1 approach.

Output: PBOCCollector class that fetches PBoC balance sheet data, registered with collector registry.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-global-cb-collectors/02-RESEARCH.md

# Prior work - Apps Script used foreign reserves as proxy
@.planning/reference/appscript_v3.4.1.md

# Source files - patterns to follow
@src/liquidity/collectors/fred.py
@src/liquidity/collectors/base.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add beautifulsoup4 and lxml dependencies</name>
  <files>pyproject.toml</files>
  <action>
Add scraping dependencies to pyproject.toml:

```toml
dependencies = [
    ...
    # Phase 2: Global CB collectors - PBoC scraping
    "beautifulsoup4>=4.12.0",
    "lxml>=5.0.0",
]
```

Run `uv sync` to install.

Note: lxml is faster than html.parser and handles malformed HTML better.
  </action>
  <verify>uv run python -c "from bs4 import BeautifulSoup; import lxml; print('scraping libs imported')"</verify>
  <done>beautifulsoup4 and lxml installed and importable</done>
</task>

<task type="auto">
  <name>Task 2: Create PBOCCollector with dual strategy</name>
  <files>src/liquidity/collectors/pboc.py</files>
  <action>
Create PBOCCollector with scraping primary and FRED fallback:

```python
"""People's Bank of China collector.

Primary: Scrape official HTM/XLS files from PBoC website
Fallback: Use FRED TRESEGCNM052N (China foreign reserves) as proxy

Note: PBoC data has ~1 month lag. This is accepted per project requirements.
"""

import asyncio
import logging
from datetime import datetime

import httpx
import pandas as pd
from bs4 import BeautifulSoup

from liquidity.collectors.base import BaseCollector, CollectorFetchError
from liquidity.collectors.registry import registry

logger = logging.getLogger(__name__)

# PBoC balance sheet page - VERIFIED WORKING (discovery sprint)
# Returns HTTP 200 with 27 HTM/XLS download links
PBOC_BALANCE_SHEET_URL = "http://www.pbc.gov.cn/en/3688247/3688975/3718249/4503799/index.html"

# FRED fallback (foreign reserves as proxy - same as Apps Script)
FRED_CHINA_RESERVES = "TRESEGCNM052N"

UNIT_MAP: dict[str, str] = {
    "PBOC_TOTAL_ASSETS": "hundreds_millions_cny",  # PBoC reports in 100 million CNY
    "CHINA_FOREIGN_RESERVES": "millions_usd",  # FRED series in millions USD
}


class PBOCCollector(BaseCollector[pd.DataFrame]):
    """PBoC collector with scraping and FRED fallback."""

    def __init__(
        self,
        name: str = "pboc",
        use_fred_fallback: bool = True,  # Use FRED if scraping fails
        **kwargs,
    ):
        super().__init__(name=name, **kwargs)
        self._use_fred_fallback = use_fred_fallback

    async def collect(
        self,
        start_date: datetime | None = None,
        end_date: datetime | None = None,
    ) -> pd.DataFrame:
        """Collect PBoC balance sheet data.

        Tries scraping first, falls back to FRED foreign reserves if scraping fails.
        """
        try:
            return await self._collect_via_scraping()
        except Exception as e:
            logger.warning("PBoC scraping failed: %s", e)
            if self._use_fred_fallback:
                logger.info("Falling back to FRED China foreign reserves")
                return await self._collect_via_fred(start_date, end_date)
            raise

    async def _collect_via_scraping(self) -> pd.DataFrame:
        """Scrape PBoC balance sheet from official website."""
        async def _fetch():
            async with httpx.AsyncClient(timeout=30.0) as client:
                # 1. Fetch index page to find latest report links
                response = await client.get(PBOC_BALANCE_SHEET_URL)
                response.raise_for_status()

                soup = BeautifulSoup(response.text, 'lxml')

                # 2. Find HTM file links (balance sheet tables)
                htm_links = [
                    a['href'] for a in soup.find_all('a', href=True)
                    if a['href'].endswith('.htm')
                ]

                if not htm_links:
                    raise CollectorFetchError("No HTM files found on PBoC page")

                # 3. Download and parse the latest HTM file
                latest_url = htm_links[0]  # Assuming most recent first
                if not latest_url.startswith('http'):
                    latest_url = f"http://www.pbc.gov.cn{latest_url}"

                htm_response = await client.get(latest_url)
                htm_response.raise_for_status()

                return self._parse_pboc_html(htm_response.text)

        return await self.fetch_with_retry(_fetch)

    def _parse_pboc_html(self, html: str) -> pd.DataFrame:
        """Parse PBoC HTM balance sheet table."""
        # Use pandas.read_html to extract tables
        tables = pd.read_html(html)

        # Find table with "Total Assets" row
        for table in tables:
            if any("Total" in str(col) for col in table.columns):
                # Found the balance sheet table
                # Extract total assets value
                ...
                break

        # Return standardized format
        return pd.DataFrame({
            "timestamp": ...,
            "series_id": "PBOC_TOTAL_ASSETS",
            "source": "pboc",
            "value": ...,
            "unit": "hundreds_millions_cny",
        })

    async def _collect_via_fred(
        self,
        start_date: datetime | None,
        end_date: datetime | None,
    ) -> pd.DataFrame:
        """Fallback: Fetch China foreign reserves from FRED."""
        from liquidity.collectors.fred import FredCollector

        fred = FredCollector()
        df = await fred.collect([FRED_CHINA_RESERVES], start_date, end_date)

        # Relabel for PBoC context
        df["series_id"] = "CHINA_FOREIGN_RESERVES"
        df["source"] = "fred_proxy"

        logger.info("Using FRED China foreign reserves as PBoC proxy")
        return df


registry.register("pboc", PBOCCollector)
```

Key implementation notes:
1. Primary: Scrape HTM files from PBoC English website
2. Fallback: Use FRED TRESEGCNM052N (same as Apps Script v3.4.1)
3. Accept ~1 month data lag (per project requirements)
4. PBoC reports in hundreds of millions CNY (亿元)
5. Robust error handling - scraping may break, fallback should always work
  </action>
  <verify>uv run python -c "from liquidity.collectors.pboc import PBOCCollector; c = PBOCCollector(); print(c)"</verify>
  <done>PBOCCollector class exists with dual strategy implementation</done>
</task>

<task type="auto">
  <name>Task 3: Test and refine PBoC scraping logic</name>
  <files>src/liquidity/collectors/pboc.py, tests/integration/test_global_cb_collectors.py</files>
  <action>
Discovery sprint findings:
- URL WORKS: HTTP 200 status
- Found 27 download links (HTM/XLS files)
- Links include: balance sheet, money stats, forex reserves
- Sample link: /goutongjiaoliu/113456/113469/4640322/index.html

1. Test the scraping logic against live PBoC website:
   - URL verified working ✓
   - 27 HTM/XLS files available
   - Need to parse HTML structure of balance sheet tables

2. Refine _parse_pboc_html() based on actual HTML structure:
   - PBoC may use Chinese + English headers
   - Table structure may vary by report date
   - Add robust parsing with fallbacks

3. Add integration tests:

```python
class TestPBOCCollector:
    """Tests for PBoC collector."""

    @pytest.mark.integration
    async def test_pboc_collect_with_fallback(self):
        """Test PBoC collection (scraping or FRED fallback)."""
        collector = PBOCCollector(use_fred_fallback=True)
        df = await collector.collect()

        assert not df.empty
        assert "timestamp" in df.columns
        assert "value" in df.columns

    @pytest.mark.integration
    async def test_pboc_fred_fallback_works(self):
        """Test FRED fallback explicitly."""
        collector = PBOCCollector(use_fred_fallback=True)
        df = await collector._collect_via_fred(None, None)

        assert not df.empty
        assert df["series_id"].iloc[0] in ["CHINA_FOREIGN_RESERVES", "TRESEGCNM052N"]

    @pytest.mark.integration
    async def test_pboc_scraping_attempt(self):
        """Test scraping attempt (may fail, that's OK)."""
        collector = PBOCCollector(use_fred_fallback=False)
        try:
            df = await collector._collect_via_scraping()
            # If scraping works, verify data
            assert not df.empty
            assert df["source"].iloc[0] == "pboc"
        except CollectorFetchError:
            # Scraping failed - acceptable, document why
            pytest.skip("PBoC scraping failed - HTML structure may have changed")
```

Tests should:
1. Verify fallback always works (FRED is reliable)
2. Attempt scraping but accept failure
3. Document any scraping issues for future maintenance
  </action>
  <verify>uv run pytest tests/integration/test_global_cb_collectors.py::TestPBOCCollector -v --tb=short</verify>
  <done>PBoC scraping tested and refined, FRED fallback verified</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `uv run ruff check src/liquidity/collectors/pboc.py` passes
- [ ] `uv run mypy src/liquidity/collectors/pboc.py` passes
- [ ] `uv run pytest tests/integration/test_global_cb_collectors.py -v -k pboc` passes
- [ ] PBOCCollector fallback to FRED always works
- [ ] Scraping attempt documented (success or failure reason)
</verification>

<success_criteria>

- beautifulsoup4 and lxml dependencies added
- PBOCCollector class follows BaseCollector pattern
- Scraping logic attempts PBoC website
- FRED fallback (TRESEGCNM052N) works reliably
- Data normalized to standard format
- Integration tests pass (with fallback if scraping fails)
</success_criteria>

<output>
After completion, create `.planning/phases/02-global-cb-collectors/02-05-SUMMARY.md`
</output>
