---
phase: 02-global-cb-collectors
plan: 03
type: execute
wave: 1
depends_on: []
files_modified: [src/liquidity/collectors/boe.py, tests/integration/test_global_cb_collectors.py]
autonomous: true
---

<objective>
Create Bank of England collector using direct CSV download.

Purpose: FRED series BOEBSTAUKA was discontinued in 2016. BoE provides current data via their database with CSV download endpoint. This collector fetches BoE balance sheet data directly from the source.

Output: BOECollector class that fetches BoE weekly balance sheet via CSV download, registered with collector registry.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-global-cb-collectors/02-RESEARCH.md

# Prior work
@.planning/phases/01-foundation-core-data/01-02-SUMMARY.md

# Source files - patterns to follow
@src/liquidity/collectors/fred.py
@src/liquidity/collectors/base.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create BOECollector class with CSV download</name>
  <files>src/liquidity/collectors/boe.py</files>
  <action>
Create BOECollector that fetches data from BoE database CSV endpoint:

```python
"""Bank of England collector using direct CSV download.

FRED series BOEBSTAUKA discontinued 2016. This collector uses BoE's
database endpoint for current balance sheet data.

CSV endpoint format:
https://www.bankofengland.co.uk/boeapps/database/_iadb-fromshowcolumns.asp?csv.x=yes&Datefrom=01/Jan/2020&Dateto=now&SeriesCodes=XXXX&UsingCodes=Y&CSVF=TN
"""

import asyncio
import io
import logging
from datetime import datetime

import httpx
import pandas as pd

from liquidity.collectors.base import BaseCollector, CollectorFetchError
from liquidity.collectors.registry import registry

logger = logging.getLogger(__name__)

# BoE series codes (RPQB prefix for weekly report data)
# Need to search BoE database for exact total assets series code
SERIES_MAP: dict[str, str] = {
    "boe_total_assets": "TBD",  # Search BoE database for total assets
}

UNIT_MAP: dict[str, str] = {
    # BoE typically reports in millions GBP
}


class BOECollector(BaseCollector[pd.DataFrame]):
    """Bank of England collector via CSV download."""

    BASE_URL = "https://www.bankofengland.co.uk/boeapps/database/_iadb-fromshowcolumns.asp"

    def __init__(self, name: str = "boe", **kwargs):
        super().__init__(name=name, **kwargs)

    async def collect(
        self,
        series_codes: list[str] | None = None,
        start_date: datetime | None = None,
        end_date: datetime | None = None,
    ) -> pd.DataFrame:
        """Collect BoE data via CSV download."""
        if series_codes is None:
            series_codes = list(SERIES_MAP.values())

        async def _fetch():
            params = {
                "csv.x": "yes",
                "Datefrom": start_date.strftime("%d/%b/%Y") if start_date else "01/Jan/2020",
                "Dateto": "now" if end_date is None else end_date.strftime("%d/%b/%Y"),
                "SeriesCodes": ",".join(series_codes),
                "UsingCodes": "Y",
                "CSVF": "TN",  # Tabular without titles
            }

            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(self.BASE_URL, params=params)
                response.raise_for_status()
                return self._parse_csv(response.text, series_codes)

        return await self.fetch_with_retry(_fetch)

    def _parse_csv(self, csv_text: str, series_codes: list[str]) -> pd.DataFrame:
        """Parse BoE CSV response to standard format."""
        df = pd.read_csv(io.StringIO(csv_text))
        # Normalize to standard format...
        # Return: timestamp, series_id, source, value, unit
        ...


registry.register("boe", BOECollector)
```

Key implementation notes:
1. Use httpx for async HTTP (already in project)
2. CSV endpoint format documented in research
3. Date format is DD/MMM/YYYY (e.g., 01/Jan/2020)
4. CSVF=TN gives tabular format without titles
5. Parse CSV into standard DataFrame format
  </action>
  <verify>uv run python -c "from liquidity.collectors.boe import BOECollector; c = BOECollector(); print(c)"</verify>
  <done>BOECollector class exists with CSV download implementation</done>
</task>

<task type="auto">
  <name>Task 2: Identify BoE total assets series code</name>
  <files>src/liquidity/collectors/boe.py</files>
  <action>
Research and identify the correct BoE series code for total assets:

1. Check BoE database search: https://www.bankofengland.co.uk/boeapps/database/
2. Search for "total assets" or "balance sheet"
3. Weekly report series have RPQB prefix
4. Series codes are 7 characters

From research, BoE weekly report is at:
https://www.bankofengland.co.uk/weekly-report/balance-sheet-and-weekly-report

Try these approaches:
1. Search BoE database for "total assets"
2. Check the weekly report HTML for series codes
3. Test with known RPQB series codes

Update SERIES_MAP and UNIT_MAP with discovered series.

Fallback: If series code search fails, document the manual search process and use placeholder that can be updated.
  </action>
  <verify>Test the endpoint URL manually or with httpx to confirm series code works</verify>
  <done>BoE total assets series code identified and documented</done>
</task>

<task type="auto">
  <name>Task 3: Add integration tests for BOECollector</name>
  <files>tests/integration/test_global_cb_collectors.py</files>
  <action>
Add integration tests for BOECollector:

```python
class TestBOECollector:
    """Tests for Bank of England collector."""

    @pytest.mark.integration
    async def test_boe_collect_balance_sheet(self):
        """Test fetching BoE balance sheet data."""
        collector = BOECollector()
        df = await collector.collect()

        assert not df.empty
        assert "timestamp" in df.columns
        assert "value" in df.columns
        assert "unit" in df.columns
        assert df["source"].iloc[0] == "boe"

    @pytest.mark.integration
    async def test_boe_data_format(self):
        """Test BoE data has expected format."""
        collector = BOECollector()
        df = await collector.collect()

        # Values should be positive (millions GBP)
        assert (df["value"] > 0).all()
        # Unit should be millions_gbp
        assert df["unit"].iloc[0] == "millions_gbp"
```

Tests should:
1. Verify CSV download works
2. Verify data is parsed correctly
3. Verify units are preserved
4. Handle network errors gracefully (skip if BoE endpoint unavailable)
  </action>
  <verify>uv run pytest tests/integration/test_global_cb_collectors.py::TestBOECollector -v --tb=short</verify>
  <done>Integration tests exist and pass</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `uv run ruff check src/liquidity/collectors/boe.py` passes
- [ ] `uv run mypy src/liquidity/collectors/boe.py` passes
- [ ] `uv run pytest tests/integration/test_global_cb_collectors.py -v -k boe` passes
- [ ] BOECollector successfully fetches BoE balance sheet data
</verification>

<success_criteria>

- BOECollector class follows BaseCollector pattern
- CSV download endpoint works correctly
- BoE total assets series identified (or documented for manual discovery)
- Data normalized to standard format with GBP units
- Integration tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-global-cb-collectors/02-03-SUMMARY.md`
</output>
